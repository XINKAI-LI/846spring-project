{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "optional-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Bad credentials', 'documentation_url': 'https://docs.github.com/rest'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time \n",
    "\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "\n",
    "\n",
    "token = \"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\"\n",
    "headers = {'Authorization': \"Token \" + token}\n",
    "rate_limit_url = \"https://api.github.com/rate_limit\"\n",
    "req = requests.get(rate_limit_url, headers=headers).json()\n",
    "print(req)\n",
    "\n",
    "##  kubernetes.kubernetes    64,671\n",
    "##  elastic.elasticsearch     47,333\n",
    "##  rails.rails           27,685\n",
    "##  tensorflow.tensorflow     18,186\n",
    "##  django.django            14,559\n",
    "##  electron.electron        14,223\n",
    "##  twbs.bootstrapJavaScript   12,700\n",
    "##  facebook.react          11045\n",
    "##  microsoft.vscode        9,842 done\n",
    "##  redis.redis             4,232 done\n",
    "\n",
    "repo_name_list = ['facebook.react'] \n",
    "############################### project info ###################\n",
    "# repo_popularity : stars  (direct)\n",
    "# repo_team_size: number of contributors (direct)\n",
    "# repo_created_date: calculate time difference between PR and project created data (direct)\n",
    "# repo_external_contributors:  outsiders' PR ratio (need outsider list and main list)\n",
    "\n",
    "\n",
    "####################### user info ######################\n",
    "# user_popularity: number of followers (direct)\n",
    "# user_tenure: calculate time difference between PR and user created data (direct)\n",
    "# user_experience: #PR of submitter  (direct)\n",
    "# user_continent: user's nation -> continent (direct)\n",
    "\n",
    "# main_member: indicator for main contirbutor  (need outsider list and main list)\n",
    "\n",
    "# user_watched: indicator for submitter watches this repo (done)\n",
    "# user_succ_rate: past success ratio of submitter's PR (done)\n",
    "\n",
    "#### build the main-outsider list #########\n",
    "# get all PR merged approver's login (main)\n",
    "# get all PR's author's login\n",
    "\n",
    "####################### PR info ###########################\n",
    "\n",
    "# pr_files_changed:  (direct) (Done)\n",
    "# LOC: (direct) (Done)\n",
    "# work_commits: \n",
    "# pr_num_comments: (user reviews to get)\n",
    "# pr_num_commits: (compare time for commits_list to get)\n",
    "# reviewer sets: (Done)\n",
    "\n",
    "# user_login: x  (direct) (Done)\n",
    "#  commits-url: y (direct) (Done)\n",
    "# comments-url: y (direct) (not work) (Done)\n",
    "\n",
    "#### independent variables of PR\n",
    "# race: user_login -> full_name -> race\n",
    "\n",
    "#### dependent variables of PR\n",
    "#review_commits: y (todo) (Done)\n",
    "#review_comments: y (todo) (Done)\n",
    "\n",
    "# 'created-at': y  (direct) (Done)\n",
    "# 'merged-at': y (direct) (Done)\n",
    "# first_review_comment_at: y (direct) (Done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "chief-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook.react\n",
      "project facebook.react has 0 user and 0 main_user\n",
      "facebook.react\n"
     ]
    }
   ],
   "source": [
    "### get the main and outside contributors\n",
    "main_user_dic = {} # key: project_name, value: set(login)\n",
    "user_dic = {} # key: project_name, value: set(login)\n",
    "reviewer_user_dic = {}  # key: project_name, value: set(login)\n",
    "\n",
    "\n",
    "PR_dic = {} # key: PR_url, value: author login, created_at\n",
    "PR_info_dic = {} # key: PR_url, value: PR_info_dic\n",
    "\n",
    "start_time =  time.time()\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    main_login_set = set()\n",
    "    user_login_set = set()\n",
    "    reviewer_login_set = set()\n",
    "    owner = repo_name.split(\".\")[0]\n",
    "    repo = repo_name.split(\".\")[1]\n",
    "    page_num = 4\n",
    "    \n",
    "    while(True):\n",
    "        # go through all merged PR to get author and reviewers and other information\n",
    "        ac_PR = \"https://api.github.com/repos/\" + owner + '/' + repo + \"/pulls?state=closed&per_page=100&page=\" + str(page_num) \n",
    "        PR_req = requests.get(ac_PR, headers=headers).json()\n",
    "        if len(PR_req) <= 2: break\n",
    "        print(\"page num: \" + str(page_num))\n",
    "        page_num += 1\n",
    "        ##################### stop standard #####################\n",
    "        if page_num >= 30 or int(PR_req[0]['created_at'].split(\"-\")[0]) < 2020:\n",
    "            break\n",
    "        ##################### take a break condition ########\n",
    "\n",
    "        req = requests.get(rate_limit_url, headers=headers).json()\n",
    "        used_token = req['rate']['used']\n",
    "        print(\"used token: \" + str(used_token))\n",
    "        if used_token >= 4000:\n",
    "            cur_time = time.time()\n",
    "            wait_time = max(60, 3600 - (cur_time - start_time))\n",
    "            print(\"wait time: \" + str(wait_time))\n",
    "            time.sleep(wait_time)\n",
    "            start_time = cur_time\n",
    "            \n",
    "        for item in PR_req:\n",
    "            if item[\"merged_at\"] != None :\n",
    "                ############ PR_dic part #############\n",
    "                pr_url = item['url']\n",
    "                PR_dic[pr_url] = {\n",
    "                    'author_login': item['user']['login'],\n",
    "                    'create_at': item['created_at']\n",
    "                }\n",
    "                ################# main and all user part #####################\n",
    "                ## save author info into user_login set\n",
    "                user_login_set.add(item['user']['login'])\n",
    "                \n",
    "                ## get the reviews' author and save into main_login\n",
    "                reviews_req = requests.get(pr_url + \"/reviews\", headers=headers).json()\n",
    "                reviewers_set = set()\n",
    "                review_comments = 0\n",
    "                first_review_date = datetime.strptime(item[\"merged_at\"], date_format)\n",
    "                #print(pr_url)\n",
    "                for review_item in reviews_req:\n",
    "                    if review_item is None: break\n",
    "                    if review_item['user'] is None: break\n",
    "                    reviewers_set.add(review_item['user']['login'])\n",
    "                    reviewer_login_set.add(review_item['user']['login'])\n",
    "                    ### number of review comments + first review comments + reviewers_set\n",
    "                    cur_review_date =  datetime.strptime(review_item[\"submitted_at\"], date_format)\n",
    "                    if cur_review_date < first_review_date:\n",
    "                        first_review_date = cur_review_date\n",
    "                    if review_item['state'] != \"APPROVED\":\n",
    "                        review_comments += 1\n",
    "                full_PRinfo_json = requests.get(pr_url, headers=headers).json()\n",
    "                print(pr_url)\n",
    "                main_login_set.add(full_PRinfo_json['merged_by']['login'])\n",
    "                ########### PR_info_dic part #############\n",
    "                if len(reviewers_set) == 0:\n",
    "                    continue\n",
    "                user_json = requests.get(\"https://api.github.com/users/\" + item['user']['login'], headers=headers).json()\n",
    "                author_name = user_json['name']\n",
    "                if author_name is not None:\n",
    "                    ### number of work_commits and review_commits\n",
    "                    commits_json = requests.get(pr_url + \"/commits\", headers=headers).json()\n",
    "                    review_commit_num = 0\n",
    "                    pr_create_date = datetime.strptime(item[\"created_at\"], date_format)\n",
    "                    for commit_item in commits_json:\n",
    "                        commit_date = datetime.strptime(commit_item[\"commit\"]['author']['date'], date_format)\n",
    "                        if commit_date > pr_create_date:\n",
    "                            review_commit_num += 1\n",
    "                    ######## save info into PR_info_dic #######\n",
    "                    \n",
    "                    PR_info_dic[pr_url] = {\n",
    "                        'pr_author_login': item['user']['login'],\n",
    "                        'pr_author_name': author_name,\n",
    "                        'pr_create_at': item['created_at'],\n",
    "                        'pr_merged_at': item['merged_at'],\n",
    "                        'pr_changed_files': full_PRinfo_json['changed_files'],\n",
    "                        'pr_LOC': full_PRinfo_json['additions'] + full_PRinfo_json['deletions'],\n",
    "                        'pr_reviewers': reviewers_set,\n",
    "                        'pr_first_review_at': first_review_date,\n",
    "                        'pr_review_commits': review_commit_num,\n",
    "                        'pr_review_comments' : review_comments,\n",
    "                        'pr_commits': full_PRinfo_json['commits']\n",
    "                    }\n",
    "    reviewer_user_dic[repo_name] = reviewer_login_set\n",
    "    main_user_dic[repo_name] = main_login_set \n",
    "    user_dic[repo_name] =  user_login_set\n",
    "    \n",
    "for repo_name in repo_name_list:\n",
    "    user_num = len(user_dic[repo_name])\n",
    "    main_num =  len(main_user_dic[repo_name])\n",
    "    print(\"project {} has {} user and {} main_user\".format(repo_name, user_num, main_num))\n",
    "    \n",
    "print_size = 3\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    cur_print = 0\n",
    "    for pr_info_item in PR_info_dic:\n",
    "        print(PR_info_dic[pr_info_item])\n",
    "        print(\"-----------------------\")\n",
    "        cur_print += 1\n",
    "        if cur_print >= print_size:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### project info #####\n",
    "# repo_popularity : stars  (direct)\n",
    "# repo_team_size: number of contributors (direct)\n",
    "# repo_created_date: calculate time difference between PR and project created data (direct)\n",
    "# repo_external_contributors:  outsiders' PR ratio (need outsider list and main list)\n",
    "\n",
    "repo_dic = {} #key project_name, value: info_set\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    owner = repo_name.split(\".\")[0]\n",
    "    repo = repo_name.split(\".\")[1]\n",
    "    ac_project = \"https://api.github.com/repos/\" + owner + '/' + repo\n",
    "    project = requests.get(ac_project, headers=headers).json()\n",
    "    outside_pr = 0.0\n",
    "    total_pr = 0.01\n",
    "    \n",
    "    # get the external_contribution\n",
    "    for pr_url in PR_dic:\n",
    "        if repo in pr_url:\n",
    "            total_pr += 1\n",
    "            if PR_dic[pr_url]['author_login'] not in main_user_dic[repo_name]:\n",
    "                outside_pr += 1\n",
    "                \n",
    "    #print(\"outside PR: {}\".format(outside_pr))\n",
    "    #print(\"total PR: {}\".format(total_pr))\n",
    "    # save all info into a repo_dic\n",
    "    repo_dic[repo_name] = {\n",
    "        \"repo_stars\": project['stargazers_count'],\n",
    "        \"repo_created_at\": project['created_at'],\n",
    "        \"repo_external_contribution\": outside_pr / total_pr,\n",
    "        \"repo_team_size\": len(user_dic[repo_name])\n",
    "    }\n",
    "\n",
    "for repo in repo_dic:\n",
    "    print(repo)\n",
    "    print(repo_dic[repo])\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### user info #####\n",
    "# user_popularity: number of followers (direct)\n",
    "# user_tenure: calculate time difference between PR and user created data (direct)\n",
    "# user_experience: #PR of submitter  (direct)\n",
    "# user_continent: user's nation -> continent (direct)\n",
    "\n",
    "# main_member: indicator for main contirbutor  (need outsider list and main list)\n",
    "# user_watched: indicator for submitter watches this repo (todo)\n",
    "# user_succ_rate: past success ratio of submitter's PR (todo)\n",
    "\n",
    "user_info_dic = {}\n",
    "start_time = time.time()\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    user_set = user_dic[repo_name]\n",
    "    print(repo_name)\n",
    "    project_user_dic = {}\n",
    "    for use_id in user_set:\n",
    "        owner = repo_name.split(\".\")[0]\n",
    "        repo = repo_name.split(\".\")[1]\n",
    "        repo_slash_name = owner + '/' + repo\n",
    "        ac_user =  \"https://api.github.com/users/\" + use_id\n",
    "        user_json = requests.get(ac_user, headers=headers).json()\n",
    "        ############# condition to take a break ##########\n",
    "        req = requests.get(rate_limit_url, headers=headers).json()\n",
    "        used_token = req['rate']['used']\n",
    "        print(\"used token: \" + str(used_token))\n",
    "        if used_token >= 4200:\n",
    "            cur_time = time.time()\n",
    "            wait_time = max(60, 3600 - (cur_time - start_time))\n",
    "            print(\"wait \" + str(wait_time))\n",
    "            time.sleep(wait_time)\n",
    "            start_time = cur_time\n",
    "            \n",
    "        # decide main member\n",
    "        main = 0 # 1 for yes 0 for no\n",
    "        if use_id in main_user_dic[repo_name]:\n",
    "            main = 1\n",
    "            \n",
    "        # decide if submitter watches this repo\n",
    "        watch = 0 # 1 for yes 0 for no\n",
    "        page_num = 1\n",
    "        while(True):\n",
    "            starred_json = requests.get(ac_user + '/starred?per_page=100&page=' + str(page_num), headers=headers).json()\n",
    "            if len(starred_json) <= 1 or watch == 1:\n",
    "                break\n",
    "            page_num += 1\n",
    "            for star_project in starred_json:\n",
    "                if star_project['full_name'] == repo_slash_name:\n",
    "                    watch = 1\n",
    "                    break\n",
    "        \n",
    "        ################### get past success ratio of submitter's PR #################\n",
    "        total_pr = 0.01\n",
    "        succ_pr = 0.0\n",
    "        repo_pr = 0.0\n",
    "        page_num = 1\n",
    "        while(True):\n",
    "            event_json = requests.get(ac_user + '/events?per_page=100&page='  + str(page_num), headers=headers).json()\n",
    "            if len(event_json) <= 2:\n",
    "                break\n",
    "            #print(\"current page num: {}\".format(page_num))\n",
    "            #print(\"total pr num: {}\".format(total_pr))\n",
    "            #print(\"succ pr num: {}\".format(succ_pr))\n",
    "            page_num += 1\n",
    "            for event in event_json:\n",
    "                if event['type'] == \"PullRequestEvent\":\n",
    "                    total_pr += 1\n",
    "                    # check if this pull request is merged\n",
    "                    api_pr = event['payload']['pull_request']['url']\n",
    "                    pr_json = requests.get(api_pr, headers=headers).json()\n",
    "                    if len(pr_json) <= 2:\n",
    "                        continue\n",
    "                    if pr_json['merged_at'] is not None and pr_json['state'] == \"closed\":\n",
    "                        succ_pr += 1\n",
    "                    # check if this PR is belong to this repo\n",
    "                    if event['repo']['name'] == repo_slash_name:\n",
    "                        repo_pr += 1\n",
    "        # save info into a dic_item\n",
    "        # print(succ_pr / total_pr)\n",
    "        project_user_dic[use_id] = {\n",
    "            \"user_followers\": user_json['followers'],\n",
    "            \"user_created_at\": user_json['created_at'],\n",
    "            \"user_experience\": total_pr,\n",
    "            \"user_repo_experience\": repo_pr,\n",
    "            \"user_main_member\": main,\n",
    "            \"user_watched\": watch,\n",
    "            \"user_succ_rate\": succ_pr / total_pr\n",
    "        }\n",
    "        \n",
    "    user_info_dic[repo_name] = project_user_dic\n",
    "    \n",
    "#https://api.github.com/users/orpiske/events?per_page=100&page=2   \n",
    "print_size = 4\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    cur_print = 0\n",
    "    for use_id in user_info_dic[repo_name]:\n",
    "        print(user_info_dic[repo_name][use_id])\n",
    "        cur_print += 1\n",
    "        if cur_print >= print_size:\n",
    "            break\n",
    "    print(\"######################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for each PR_info, transfer each of its reviewer's login to full name\n",
    "\n",
    "login_name_dic = {} # key: main_login, value: full_name\n",
    "# build a login - full_name map\n",
    "\n",
    "for repo_name in reviewer_user_dic.keys():\n",
    "    for reviewer_login in reviewer_user_dic[repo_name]:\n",
    "        user_json = requests.get(\"https://api.github.com/users/\" + reviewer_login, headers=headers).json()\n",
    "        if user_json['name'] is None:\n",
    "            login_name_dic[reviewer_login] = \"Unknown\"\n",
    "        else:\n",
    "            login_name_dic[reviewer_login] =  user_json['name']\n",
    "\n",
    "# use this map to translate reviewer_login in PR_info_dic\n",
    "\n",
    "for url in PR_info_dic:\n",
    "    login_set = PR_info_dic[url]['pr_reviewers']\n",
    "    name_set = set()\n",
    "    \n",
    "    for login_item in login_set:\n",
    "        if login_name_dic[login_item] is None:\n",
    "            name_set.add('Unknown')\n",
    "        else:\n",
    "            name_set.add(login_name_dic[login_item])\n",
    "    PR_info_dic[url]['pr_reviewers'] = name_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Merge PR_info, user_info, and pj_info together ###########\n",
    "csv_column = []\n",
    "pr_features = []\n",
    "repo_features = []\n",
    "user_features = []\n",
    "\n",
    "for key in PR_info_dic:\n",
    "    pr_features = list(PR_info_dic[key].keys())\n",
    "    csv_column.extend(pr_features)\n",
    "    break\n",
    "    \n",
    "for key in repo_dic:\n",
    "    repo_features = list(repo_dic[key].keys())\n",
    "    csv_column.extend(repo_features)\n",
    "    break\n",
    "    \n",
    "for repo_key in user_info_dic:\n",
    "    for user_key in user_info_dic[repo_key]:\n",
    "        user_features = list(user_info_dic[repo_key][user_key].keys())\n",
    "        csv_column.extend(user_features)\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(csv_column)\n",
    "csv_name = \"./csv_files/\" + repo_name_list[0] + \".csv\"\n",
    "with open(csv_name, 'w') as f:\n",
    "    csv_write = csv.writer(f)\n",
    "    csv_head = csv_column\n",
    "    csv_write.writerow(csv_head)\n",
    "    #facebook.presto\n",
    "    for pr_url in PR_info_dic:\n",
    "        ## https://api.github.com/repos/apache/camel/pulls/\n",
    "        pr_info = PR_info_dic[pr_url]\n",
    "        #print(pr_url)\n",
    "        repo_name = pr_url.split(\"/\")[-4] + \".\" + pr_url.split(\"/\")[-3]\n",
    "        repo_info = repo_dic[repo_name]\n",
    "        user_info = user_info_dic[repo_name][pr_info['pr_author_login']]\n",
    "        \n",
    "        data_row = []\n",
    "        for i in range(len(pr_features)):\n",
    "            feature_str = pr_features[i]\n",
    "            data_row.append(pr_info[feature_str])\n",
    "            \n",
    "        for i in range(len(repo_features)):\n",
    "            feature_str = repo_features[i]\n",
    "            data_row.append(repo_info[feature_str])\n",
    "            \n",
    "        for i in range(len(user_features)):\n",
    "            feature_str = user_features[i]\n",
    "            data_row.append(user_info[feature_str])\n",
    "            \n",
    "        csv_write.writerow(data_row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-residence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
