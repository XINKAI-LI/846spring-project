{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "optional-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resources': {'core': {'limit': 5000, 'used': 1040, 'remaining': 3960, 'reset': 1627448913}, 'search': {'limit': 30, 'used': 0, 'remaining': 30, 'reset': 1627446476}, 'graphql': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1627450016}, 'integration_manifest': {'limit': 5000, 'used': 0, 'remaining': 5000, 'reset': 1627450016}, 'source_import': {'limit': 100, 'used': 0, 'remaining': 100, 'reset': 1627446476}, 'code_scanning_upload': {'limit': 500, 'used': 0, 'remaining': 500, 'reset': 1627450016}}, 'rate': {'limit': 5000, 'used': 1040, 'remaining': 3960, 'reset': 1627448913}}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time \n",
    "\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "\n",
    "\n",
    "token = \"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\"\n",
    "headers = {'Authorization': \"Token \" + token}\n",
    "rate_limit_url = \"https://api.github.com/rate_limit\"\n",
    "req = requests.get(rate_limit_url, headers=headers).json()\n",
    "print(req)\n",
    "\n",
    "##  kubernetes.kubernetes    64,671\n",
    "##  elastic.elasticsearch     47,333\n",
    "##  rails.rails           27,685\n",
    "##  tensorflow.tensorflow     18,186\n",
    "##  django.django            14,559\n",
    "##  electron.electron        14,223\n",
    "##  twbs.bootstrapJavaScript   12,700\n",
    "##  facebook.react          11045\n",
    "##  microsoft.vscode        9,842\n",
    "##  redis.redis             4,232\n",
    "\n",
    "repo_name_list = ['redis.redis']\n",
    "############################### project info ###################\n",
    "# repo_popularity : stars  (direct)\n",
    "# repo_team_size: number of contributors (direct)\n",
    "# repo_created_date: calculate time difference between PR and project created data (direct)\n",
    "# repo_external_contributors:  outsiders' PR ratio (need outsider list and main list)\n",
    "\n",
    "\n",
    "####################### user info ######################\n",
    "# user_popularity: number of followers (direct)\n",
    "# user_tenure: calculate time difference between PR and user created data (direct)\n",
    "# user_experience: #PR of submitter  (direct)\n",
    "# user_continent: user's nation -> continent (direct)\n",
    "\n",
    "# main_member: indicator for main contirbutor  (need outsider list and main list)\n",
    "\n",
    "# user_watched: indicator for submitter watches this repo (done)\n",
    "# user_succ_rate: past success ratio of submitter's PR (done)\n",
    "\n",
    "#### build the main-outsider list #########\n",
    "# get all PR merged approver's login (main)\n",
    "# get all PR's author's login\n",
    "\n",
    "####################### PR info ###########################\n",
    "\n",
    "# pr_files_changed:  (direct) (Done)\n",
    "# LOC: (direct) (Done)\n",
    "# work_commits: \n",
    "# pr_num_comments: (user reviews to get)\n",
    "# pr_num_commits: (compare time for commits_list to get)\n",
    "# reviewer sets: (Done)\n",
    "\n",
    "# user_login: x  (direct) (Done)\n",
    "#  commits-url: y (direct) (Done)\n",
    "# comments-url: y (direct) (not work) (Done)\n",
    "\n",
    "#### independent variables of PR\n",
    "# race: user_login -> full_name -> race\n",
    "\n",
    "#### dependent variables of PR\n",
    "#review_commits: y (todo) (Done)\n",
    "#review_comments: y (todo) (Done)\n",
    "\n",
    "# 'created-at': y  (direct) (Done)\n",
    "# 'merged-at': y (direct) (Done)\n",
    "# first_review_comment_at: y (direct) (Done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "chief-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redis.redis\n",
      "page num: 1\n",
      "used token: 1041\n",
      "page num: 2\n",
      "used token: 1346\n",
      "page num: 3\n",
      "used token: 1651\n",
      "page num: 4\n",
      "used token: 1948\n",
      "page num: 5\n",
      "used token: 2276\n",
      "page num: 6\n",
      "used token: 2598\n",
      "page num: 7\n",
      "used token: 2920\n",
      "page num: 8\n",
      "used token: 3226\n",
      "wait time: 2778.2231879234314\n",
      "page num: 9\n",
      "used token: 325\n",
      "page num: 10\n",
      "used token: 668\n",
      "page num: 11\n",
      "used token: 966\n",
      "page num: 12\n",
      "used token: 1266\n",
      "page num: 13\n",
      "used token: 1440\n",
      "page num: 14\n",
      "used token: 1620\n",
      "page num: 15\n",
      "project redis.redis has 186 user and 6 main_user\n",
      "redis.redis\n",
      "{'pr_author_login': 'oranagra', 'pr_author_name': 'Oran Agra', 'pr_create_at': '2021-07-21T15:11:39Z', 'pr_merged_at': '2021-07-21T18:07:15Z', 'pr_changed_files': 6, 'pr_LOC': 85, 'pr_reviewers': {'yossigo'}, 'pr_first_review_at': datetime.datetime(2021, 7, 21, 17, 29, 54), 'pr_review_commits': 0, 'pr_review_comments': 0, 'pr_commits': 3}\n",
      "-----------------------\n",
      "{'pr_author_login': 'oranagra', 'pr_author_name': 'Oran Agra', 'pr_create_at': '2021-07-21T15:03:36Z', 'pr_merged_at': '2021-07-21T18:07:03Z', 'pr_changed_files': 26, 'pr_LOC': 994, 'pr_reviewers': {'yossigo'}, 'pr_first_review_at': datetime.datetime(2021, 7, 21, 17, 28, 16), 'pr_review_commits': 0, 'pr_review_comments': 0, 'pr_commits': 21}\n",
      "-----------------------\n",
      "{'pr_author_login': 'oranagra', 'pr_author_name': 'Oran Agra', 'pr_create_at': '2021-07-21T13:38:14Z', 'pr_merged_at': '2021-07-21T18:06:49Z', 'pr_changed_files': 53, 'pr_LOC': 1326, 'pr_reviewers': {'yossigo'}, 'pr_first_review_at': datetime.datetime(2021, 7, 21, 17, 27, 55), 'pr_review_commits': 0, 'pr_review_comments': 0, 'pr_commits': 35}\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "### get the main and outside contributors\n",
    "main_user_dic = {} # key: project_name, value: set(login)\n",
    "user_dic = {} # key: project_name, value: set(login)\n",
    "reviewer_user_dic = {}  # key: project_name, value: set(login)\n",
    "\n",
    "\n",
    "PR_dic = {} # key: PR_url, value: author login, created_at\n",
    "PR_info_dic = {} # key: PR_url, value: PR_info_dic\n",
    "\n",
    "start_time =  time.time()\n",
    "\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    main_login_set = set()\n",
    "    user_login_set = set()\n",
    "    reviewer_login_set = set()\n",
    "    owner = repo_name.split(\".\")[0]\n",
    "    repo = repo_name.split(\".\")[1]\n",
    "    page_num = 1\n",
    "    \n",
    "    while(True):\n",
    "        # go through all merged PR to get author and reviewers and other information\n",
    "        ac_PR = \"https://api.github.com/repos/\" + owner + '/' + repo + \"/pulls?state=closed&per_page=100&page=\" + str(page_num) \n",
    "        PR_req = requests.get(ac_PR, headers=headers).json()\n",
    "        if len(PR_req) <= 2: break\n",
    "        print(\"page num: \" + str(page_num))\n",
    "        page_num += 1\n",
    "        ##################### stop standard #####################\n",
    "        if page_num >= 30 or int(PR_req[0]['created_at'].split(\"-\")[0]) < 2020:\n",
    "            break\n",
    "        ##################### take a break condition ########\n",
    "\n",
    "        req = requests.get(rate_limit_url, headers=headers).json()\n",
    "        used_token = req['rate']['used']\n",
    "        print(\"used token: \" + str(used_token))\n",
    "        if used_token >= 4000:\n",
    "            cur_time = time.time()\n",
    "            wait_time = 3600 - (cur_time - start_time)\n",
    "            print(\"wait time: \" + str(wait_time))\n",
    "            time.sleep(wait_time)\n",
    "            start_time = cur_time\n",
    "            \n",
    "        for item in PR_req:\n",
    "            if item[\"merged_at\"] != None :\n",
    "                ############ PR_dic part #############\n",
    "                pr_url = item['url']\n",
    "                PR_dic[pr_url] = {\n",
    "                    'author_login': item['user']['login'],\n",
    "                    'create_at': item['created_at']\n",
    "                }\n",
    "                ################# main and all user part #####################\n",
    "                ## save author info into user_login set\n",
    "                user_login_set.add(item['user']['login'])\n",
    "                \n",
    "                ## get the reviews' author and save into main_login\n",
    "                reviews_req = requests.get(pr_url + \"/reviews\", headers=headers).json()\n",
    "                reviewers_set = set()\n",
    "                review_comments = 0\n",
    "                first_review_date = datetime.strptime(item[\"merged_at\"], date_format)\n",
    "                \n",
    "                for review_item in reviews_req:\n",
    "                    reviewers_set.add(review_item['user']['login'])\n",
    "                    reviewer_login_set.add(review_item['user']['login'])\n",
    "                    ### number of review comments + first review comments + reviewers_set\n",
    "                    cur_review_date =  datetime.strptime(review_item[\"submitted_at\"], date_format)\n",
    "                    if cur_review_date < first_review_date:\n",
    "                        first_review_date = cur_review_date\n",
    "                    if review_item['state'] != \"APPROVED\":\n",
    "                        review_comments += 1\n",
    "                full_PRinfo_json = requests.get(pr_url, headers=headers).json()\n",
    "                main_login_set.add(full_PRinfo_json['merged_by']['login'])\n",
    "                ########### PR_info_dic part #############\n",
    "                if len(reviewers_set) == 0:\n",
    "                    continue\n",
    "                user_json = requests.get(\"https://api.github.com/users/\" + item['user']['login'], headers=headers).json()\n",
    "                author_name = user_json['name']\n",
    "                if author_name is not None:\n",
    "                    ### number of work_commits and review_commits\n",
    "                    commits_json = requests.get(pr_url + \"/commits\", headers=headers).json()\n",
    "                    review_commit_num = 0\n",
    "                    pr_create_date = datetime.strptime(item[\"created_at\"], date_format)\n",
    "                    for commit_item in commits_json:\n",
    "                        commit_date = datetime.strptime(commit_item[\"commit\"]['author']['date'], date_format)\n",
    "                        if commit_date > pr_create_date:\n",
    "                            review_commit_num += 1\n",
    "                    ######## save info into PR_info_dic #######\n",
    "                    \n",
    "                    PR_info_dic[pr_url] = {\n",
    "                        'pr_author_login': item['user']['login'],\n",
    "                        'pr_author_name': author_name,\n",
    "                        'pr_create_at': item['created_at'],\n",
    "                        'pr_merged_at': item['merged_at'],\n",
    "                        'pr_changed_files': full_PRinfo_json['changed_files'],\n",
    "                        'pr_LOC': full_PRinfo_json['additions'] + full_PRinfo_json['deletions'],\n",
    "                        'pr_reviewers': reviewers_set,\n",
    "                        'pr_first_review_at': first_review_date,\n",
    "                        'pr_review_commits': review_commit_num,\n",
    "                        'pr_review_comments' : review_comments,\n",
    "                        'pr_commits': full_PRinfo_json['commits']\n",
    "                    }\n",
    "    reviewer_user_dic[repo_name] = reviewer_login_set\n",
    "    main_user_dic[repo_name] = main_login_set \n",
    "    user_dic[repo_name] =  user_login_set\n",
    "    \n",
    "for repo_name in repo_name_list:\n",
    "    user_num = len(user_dic[repo_name])\n",
    "    main_num =  len(main_user_dic[repo_name])\n",
    "    print(\"project {} has {} user and {} main_user\".format(repo_name, user_num, main_num))\n",
    "    \n",
    "print_size = 3\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    cur_print = 0\n",
    "    for pr_info_item in PR_info_dic:\n",
    "        print(PR_info_dic[pr_info_item])\n",
    "        print(\"-----------------------\")\n",
    "        cur_print += 1\n",
    "        if cur_print >= print_size:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "emotional-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redis.redis\n",
      "{'repo_stars': 50279, 'repo_created_at': '2009-03-21T22:32:25Z', 'repo_external_contribution': 0.6185697153316922, 'repo_team_size': 186}\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "##### project info #####\n",
    "# repo_popularity : stars  (direct)\n",
    "# repo_team_size: number of contributors (direct)\n",
    "# repo_created_date: calculate time difference between PR and project created data (direct)\n",
    "# repo_external_contributors:  outsiders' PR ratio (need outsider list and main list)\n",
    "\n",
    "repo_dic = {} #key project_name, value: info_set\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    owner = repo_name.split(\".\")[0]\n",
    "    repo = repo_name.split(\".\")[1]\n",
    "    ac_project = \"https://api.github.com/repos/\" + owner + '/' + repo\n",
    "    project = requests.get(ac_project, headers=headers).json()\n",
    "    outside_pr = 0.0\n",
    "    total_pr = 0.01\n",
    "    \n",
    "    # get the external_contribution\n",
    "    for pr_url in PR_dic:\n",
    "        if repo in pr_url:\n",
    "            total_pr += 1\n",
    "            if PR_dic[pr_url]['author_login'] not in main_user_dic[repo_name]:\n",
    "                outside_pr += 1\n",
    "                \n",
    "    #print(\"outside PR: {}\".format(outside_pr))\n",
    "    #print(\"total PR: {}\".format(total_pr))\n",
    "    # save all info into a repo_dic\n",
    "    repo_dic[repo_name] = {\n",
    "        \"repo_stars\": project['stargazers_count'],\n",
    "        \"repo_created_at\": project['created_at'],\n",
    "        \"repo_external_contribution\": outside_pr / total_pr,\n",
    "        \"repo_team_size\": len(user_dic[repo_name])\n",
    "    }\n",
    "\n",
    "for repo in repo_dic:\n",
    "    print(repo)\n",
    "    print(repo_dic[repo])\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "raised-fifth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redis.redis\n",
      "used token: 1\n",
      "used token: 14\n",
      "used token: 24\n",
      "used token: 43\n",
      "used token: 48\n",
      "used token: 86\n",
      "used token: 145\n",
      "used token: 153\n",
      "used token: 168\n",
      "used token: 175\n",
      "used token: 182\n",
      "used token: 227\n",
      "used token: 267\n",
      "used token: 276\n",
      "used token: 282\n",
      "used token: 288\n",
      "used token: 293\n",
      "used token: 299\n",
      "used token: 308\n",
      "used token: 315\n",
      "used token: 327\n",
      "used token: 369\n",
      "used token: 376\n",
      "used token: 381\n",
      "used token: 446\n",
      "used token: 459\n",
      "used token: 466\n",
      "used token: 471\n",
      "used token: 475\n",
      "used token: 483\n",
      "used token: 486\n",
      "used token: 492\n",
      "used token: 513\n",
      "used token: 617\n",
      "used token: 620\n",
      "used token: 639\n",
      "used token: 649\n",
      "used token: 653\n",
      "used token: 656\n",
      "used token: 659\n",
      "used token: 665\n",
      "used token: 680\n",
      "used token: 694\n",
      "used token: 724\n",
      "used token: 742\n",
      "used token: 746\n",
      "used token: 751\n",
      "used token: 758\n",
      "used token: 763\n",
      "used token: 826\n",
      "used token: 832\n",
      "used token: 839\n",
      "used token: 852\n",
      "used token: 857\n",
      "used token: 887\n",
      "used token: 890\n",
      "used token: 918\n",
      "used token: 922\n",
      "used token: 939\n",
      "used token: 998\n",
      "used token: 1001\n",
      "used token: 1004\n",
      "used token: 1008\n",
      "used token: 1015\n",
      "used token: 1065\n",
      "used token: 1074\n",
      "used token: 1077\n",
      "used token: 1082\n",
      "used token: 1086\n",
      "used token: 1090\n",
      "used token: 1100\n",
      "used token: 1105\n",
      "used token: 1108\n",
      "used token: 1117\n",
      "used token: 1122\n",
      "used token: 1129\n",
      "used token: 1158\n",
      "used token: 1164\n",
      "used token: 1171\n",
      "used token: 1248\n",
      "used token: 1273\n",
      "used token: 1278\n",
      "used token: 1324\n",
      "used token: 1345\n",
      "used token: 1362\n",
      "used token: 1368\n",
      "used token: 1372\n",
      "used token: 1381\n",
      "used token: 1390\n",
      "used token: 1458\n",
      "used token: 1461\n",
      "used token: 1490\n",
      "used token: 1496\n",
      "used token: 1499\n",
      "used token: 1504\n",
      "used token: 1519\n",
      "used token: 1527\n",
      "used token: 1543\n",
      "used token: 1571\n",
      "used token: 1576\n",
      "used token: 1579\n",
      "used token: 1605\n",
      "used token: 1612\n",
      "used token: 1617\n",
      "used token: 1623\n",
      "used token: 1639\n",
      "used token: 1647\n",
      "used token: 1656\n",
      "used token: 1661\n",
      "used token: 1666\n",
      "used token: 1669\n",
      "used token: 1680\n",
      "used token: 1687\n",
      "used token: 1692\n",
      "used token: 1710\n",
      "used token: 1728\n",
      "used token: 1740\n",
      "used token: 1745\n",
      "used token: 1757\n",
      "used token: 1798\n",
      "used token: 1808\n",
      "used token: 1813\n",
      "used token: 1867\n",
      "used token: 1871\n",
      "used token: 1877\n",
      "used token: 1883\n",
      "used token: 1888\n",
      "used token: 1892\n",
      "used token: 1896\n",
      "used token: 1919\n",
      "used token: 1940\n",
      "used token: 1948\n",
      "used token: 1953\n",
      "used token: 1985\n",
      "used token: 1992\n",
      "used token: 1997\n",
      "used token: 2007\n",
      "used token: 2011\n",
      "used token: 2030\n",
      "used token: 2036\n",
      "used token: 2039\n",
      "used token: 2047\n",
      "used token: 2052\n",
      "used token: 2058\n",
      "used token: 2099\n",
      "used token: 2134\n",
      "used token: 2141\n",
      "used token: 2147\n",
      "used token: 2193\n",
      "used token: 2202\n",
      "used token: 2211\n",
      "used token: 2214\n",
      "used token: 2219\n",
      "used token: 2255\n",
      "used token: 2260\n",
      "used token: 2264\n",
      "used token: 2285\n",
      "used token: 2321\n",
      "used token: 2347\n",
      "used token: 2352\n",
      "used token: 2395\n",
      "used token: 2404\n",
      "used token: 2412\n",
      "used token: 2439\n",
      "used token: 2443\n",
      "used token: 2449\n",
      "used token: 2456\n",
      "used token: 2459\n",
      "used token: 2494\n",
      "used token: 2502\n",
      "used token: 2505\n",
      "used token: 2508\n",
      "used token: 2526\n",
      "used token: 2544\n",
      "used token: 2652\n",
      "used token: 2657\n",
      "used token: 2669\n",
      "used token: 2673\n",
      "used token: 2679\n",
      "used token: 2693\n",
      "used token: 2714\n",
      "used token: 2729\n",
      "used token: 2734\n",
      "used token: 2738\n",
      "used token: 2746\n",
      "used token: 2750\n",
      "redis.redis\n",
      "{'user_followers': 45, 'user_created_at': '2014-06-20T13:40:24Z', 'user_experience': 3.01, 'user_repo_experience': 0.0, 'user_main_member': 0, 'user_watched': 1, 'user_succ_rate': 0.0}\n",
      "{'user_followers': 26, 'user_created_at': '2010-09-14T00:54:15Z', 'user_experience': 5.01, 'user_repo_experience': 0.0, 'user_main_member': 0, 'user_watched': 0, 'user_succ_rate': 0.5988023952095809}\n",
      "{'user_followers': 98, 'user_created_at': '2010-11-04T23:18:33Z', 'user_experience': 13.01, 'user_repo_experience': 0.0, 'user_main_member': 0, 'user_watched': 1, 'user_succ_rate': 0.9992313604919293}\n",
      "{'user_followers': 24, 'user_created_at': '2015-04-18T17:44:09Z', 'user_experience': 0.01, 'user_repo_experience': 0.0, 'user_main_member': 0, 'user_watched': 0, 'user_succ_rate': 0.0}\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "###### user info #####\n",
    "# user_popularity: number of followers (direct)\n",
    "# user_tenure: calculate time difference between PR and user created data (direct)\n",
    "# user_experience: #PR of submitter  (direct)\n",
    "# user_continent: user's nation -> continent (direct)\n",
    "\n",
    "# main_member: indicator for main contirbutor  (need outsider list and main list)\n",
    "# user_watched: indicator for submitter watches this repo (todo)\n",
    "# user_succ_rate: past success ratio of submitter's PR (todo)\n",
    "\n",
    "user_info_dic = {}\n",
    "start_time = time.time()\n",
    "\n",
    "for repo_name in repo_name_list :\n",
    "    user_set = user_dic[repo_name]\n",
    "    print(repo_name)\n",
    "    project_user_dic = {}\n",
    "    for use_id in user_set:\n",
    "        owner = repo_name.split(\".\")[0]\n",
    "        repo = repo_name.split(\".\")[1]\n",
    "        repo_slash_name = owner + '/' + repo\n",
    "        ac_user =  \"https://api.github.com/users/\" + use_id\n",
    "        user_json = requests.get(ac_user, headers=headers).json()\n",
    "        ############# condition to take a break ##########\n",
    "        req = requests.get(rate_limit_url, headers=headers).json()\n",
    "        used_token = req['rate']['used']\n",
    "        print(\"used token: \" + str(used_token))\n",
    "        if used_token >= 4000:\n",
    "            cur_time = time.time()\n",
    "            wait_time = 3600 - (cur_time - start_time)\n",
    "            print(\"wait \" + str(wait_time))\n",
    "            time.sleep(wait_time)\n",
    "            start_time = cur_time\n",
    "            \n",
    "        # decide main member\n",
    "        main = 0 # 1 for yes 0 for no\n",
    "        if use_id in main_user_dic[repo_name]:\n",
    "            main = 1\n",
    "            \n",
    "        # decide if submitter watches this repo\n",
    "        watch = 0 # 1 for yes 0 for no\n",
    "        page_num = 1\n",
    "        while(True):\n",
    "            starred_json = requests.get(ac_user + '/starred?per_page=100&page=' + str(page_num), headers=headers).json()\n",
    "            if len(starred_json) <= 1 or watch == 1:\n",
    "                break\n",
    "            page_num += 1\n",
    "            for star_project in starred_json:\n",
    "                if star_project['full_name'] == repo_slash_name:\n",
    "                    watch = 1\n",
    "                    break\n",
    "        \n",
    "        ################### get past success ratio of submitter's PR #################\n",
    "        total_pr = 0.01\n",
    "        succ_pr = 0.0\n",
    "        repo_pr = 0.0\n",
    "        page_num = 1\n",
    "        while(True):\n",
    "            event_json = requests.get(ac_user + '/events?per_page=100&page='  + str(page_num), headers=headers).json()\n",
    "            if len(event_json) <= 2:\n",
    "                break\n",
    "            #print(\"current page num: {}\".format(page_num))\n",
    "            #print(\"total pr num: {}\".format(total_pr))\n",
    "            #print(\"succ pr num: {}\".format(succ_pr))\n",
    "            page_num += 1\n",
    "            for event in event_json:\n",
    "                if event['type'] == \"PullRequestEvent\":\n",
    "                    total_pr += 1\n",
    "                    # check if this pull request is merged\n",
    "                    api_pr = event['payload']['pull_request']['url']\n",
    "                    pr_json = requests.get(api_pr, headers=headers).json()\n",
    "                    if len(pr_json) <= 2:\n",
    "                        continue\n",
    "                    if pr_json['merged_at'] is not None and pr_json['state'] == \"closed\":\n",
    "                        succ_pr += 1\n",
    "                    # check if this PR is belong to this repo\n",
    "                    if event['repo']['name'] == repo_slash_name:\n",
    "                        repo_pr += 1\n",
    "        # save info into a dic_item\n",
    "        # print(succ_pr / total_pr)\n",
    "        project_user_dic[use_id] = {\n",
    "            \"user_followers\": user_json['followers'],\n",
    "            \"user_created_at\": user_json['created_at'],\n",
    "            \"user_experience\": total_pr,\n",
    "            \"user_repo_experience\": repo_pr,\n",
    "            \"user_main_member\": main,\n",
    "            \"user_watched\": watch,\n",
    "            \"user_succ_rate\": succ_pr / total_pr\n",
    "        }\n",
    "        \n",
    "    user_info_dic[repo_name] = project_user_dic\n",
    "    \n",
    "#https://api.github.com/users/orpiske/events?per_page=100&page=2   \n",
    "print_size = 4\n",
    "for repo_name in repo_name_list :\n",
    "    print(repo_name)\n",
    "    cur_print = 0\n",
    "    for use_id in user_info_dic[repo_name]:\n",
    "        print(user_info_dic[repo_name][use_id])\n",
    "        cur_print += 1\n",
    "        if cur_print >= print_size:\n",
    "            break\n",
    "    print(\"######################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "chinese-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for each PR_info, transfer each of its reviewer's login to full name\n",
    "\n",
    "login_name_dic = {} # key: main_login, value: full_name\n",
    "# build a login - full_name map\n",
    "\n",
    "for repo_name in reviewer_user_dic.keys():\n",
    "    for reviewer_login in reviewer_user_dic[repo_name]:\n",
    "        user_json = requests.get(\"https://api.github.com/users/\" + reviewer_login, headers=headers).json()\n",
    "        if user_json['name'] is None:\n",
    "            login_name_dic[reviewer_login] = \"Unknown\"\n",
    "        else:\n",
    "            login_name_dic[reviewer_login] =  user_json['name']\n",
    "\n",
    "# use this map to translate reviewer_login in PR_info_dic\n",
    "\n",
    "for url in PR_info_dic:\n",
    "    login_set = PR_info_dic[url]['pr_reviewers']\n",
    "    name_set = set()\n",
    "    \n",
    "    for login_item in login_set:\n",
    "        if login_name_dic[login_item] is None:\n",
    "            name_set.add('Unknown')\n",
    "        else:\n",
    "            name_set.add(login_name_dic[login_item])\n",
    "    PR_info_dic[url]['pr_reviewers'] = name_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "iraqi-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pr_author_login', 'pr_author_name', 'pr_create_at', 'pr_merged_at', 'pr_changed_files', 'pr_LOC', 'pr_reviewers', 'pr_first_review_at', 'pr_review_commits', 'pr_review_comments', 'pr_commits', 'repo_stars', 'repo_created_at', 'repo_external_contribution', 'repo_team_size', 'user_followers', 'user_created_at', 'user_experience', 'user_repo_experience', 'user_main_member', 'user_watched', 'user_succ_rate']\n"
     ]
    }
   ],
   "source": [
    "######### Merge PR_info, user_info, and pj_info together ###########\n",
    "csv_column = []\n",
    "pr_features = []\n",
    "repo_features = []\n",
    "user_features = []\n",
    "\n",
    "for key in PR_info_dic:\n",
    "    pr_features = list(PR_info_dic[key].keys())\n",
    "    csv_column.extend(pr_features)\n",
    "    break\n",
    "    \n",
    "for key in repo_dic:\n",
    "    repo_features = list(repo_dic[key].keys())\n",
    "    csv_column.extend(repo_features)\n",
    "    break\n",
    "    \n",
    "for repo_key in user_info_dic:\n",
    "    for user_key in user_info_dic[repo_key]:\n",
    "        user_features = list(user_info_dic[repo_key][user_key].keys())\n",
    "        csv_column.extend(user_features)\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(csv_column)\n",
    "csv_name = \"./csv_files/\" + repo_name_list[0] + \".csv\"\n",
    "with open(csv_name, 'w') as f:\n",
    "    csv_write = csv.writer(f)\n",
    "    csv_head = csv_column\n",
    "    csv_write.writerow(csv_head)\n",
    "    #facebook.presto\n",
    "    for pr_url in PR_info_dic:\n",
    "        ## https://api.github.com/repos/apache/camel/pulls/\n",
    "        pr_info = PR_info_dic[pr_url]\n",
    "        #print(pr_url)\n",
    "        repo_name = pr_url.split(\"/\")[-4] + \".\" + pr_url.split(\"/\")[-3]\n",
    "        repo_info = repo_dic[repo_name]\n",
    "        user_info = user_info_dic[repo_name][pr_info['pr_author_login']]\n",
    "        \n",
    "        data_row = []\n",
    "        for i in range(len(pr_features)):\n",
    "            feature_str = pr_features[i]\n",
    "            data_row.append(pr_info[feature_str])\n",
    "            \n",
    "        for i in range(len(repo_features)):\n",
    "            feature_str = repo_features[i]\n",
    "            data_row.append(repo_info[feature_str])\n",
    "            \n",
    "        for i in range(len(user_features)):\n",
    "            feature_str = user_features[i]\n",
    "            data_row.append(user_info[feature_str])\n",
    "            \n",
    "        csv_write.writerow(data_row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-sleeve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
