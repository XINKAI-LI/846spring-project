{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "physical-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "csv_list = [\"redis.redis.csv\"] # [\"redis.redis.csv\"]\n",
    "\n",
    "\n",
    "##### feature index ##########\n",
    "pr_author_login_idx = 0  ### delete\n",
    "pr_author_name_idx = 1  ### replace with race\n",
    "pr_create_at_idx = 2  ### replace with notice time\n",
    "pr_merged_at_idx = 3  ### replace with review time\n",
    "pr_changed_files_idx = 4\n",
    "pr_LOC_idx = 5\n",
    "pr_reviewers_idx = 6   #### delete for hypo 1-4 , change for hypo 5\n",
    "pr_first_review_at_idx = 7  ### delete\n",
    "pr_review_commits_idx = 8\n",
    "pr_review_comments_idx = 9\n",
    "pr_commits_idx = 10\n",
    "\n",
    "repo_stars_idx = 11\n",
    "repo_created_at_idx = 12  ####  replace with repo time\n",
    "repo_external_contribution_idx = 13\n",
    "repo_team_size_idx = 14\n",
    "\n",
    "user_followers_idx = 15\n",
    "user_created_at_idx = 16   ### replace with user time\n",
    "user_experience_idx = 17\n",
    "user_repo_experience_idx = 18\n",
    "user_main_member_idx = 19\n",
    "user_watched_idx = 20\n",
    "user_succ_rate_idx = 21\n",
    "\n",
    "def set_string(reveiewers):\n",
    "    \n",
    "    reveiewers = reveiewers[1:-1]\n",
    "    reveiewer_list = reveiewers.split(\",\")\n",
    "    res = []\n",
    "    for name in reveiewer_list:\n",
    "        res.append(name[1:-1])\n",
    "    return res\n",
    "\n",
    "######### get the dictionary for user-name : race\n",
    "race_dic = {} # key name, value race\n",
    "\n",
    "for file_name in csv_list:\n",
    "    f_read = open(\"./csv_files/\" + file_name, 'r')\n",
    "    with f_read:\n",
    "        reader = csv.reader(f_read)\n",
    "        count = 0\n",
    "        for read_row in reader:\n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            author_name = read_row[pr_author_name_idx]\n",
    "            race_dic[author_name] = \"Unkonwn\"\n",
    "            for reviewer_name in set_string(read_row[pr_reviewers_idx]):\n",
    "                race_dic[reviewer_name] = \"Unkonwn\"\n",
    "#print(race_dic.keys())\n",
    "\n",
    "for name in race_dic:\n",
    "    full_name = name.replace(\" \", \"%20\")\n",
    "    #print(full_name) White API\n",
    "    ethnic_req = requests.get(\"http://www.name-prism.com/api_token/eth/json/4868133984c85190/\"+full_name).json()\n",
    "    for race, value in ethnic_req.items():\n",
    "        if value >= 0.8 and (race == \"API\" or race == \"White\" or race == \"Hispanic\"):\n",
    "            race_dic[name] = race\n",
    "            break\n",
    "    time.sleep(1.01)\n",
    "\n",
    "print(len(race_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abstract-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### build the data for hypo 1-4 ##########\n",
    "\n",
    "### the new variables for model\n",
    "pr_head1 = ['pr_author_race','pr_notice_time','pr_review_time','pr_changed_files',\n",
    "    'pr_LOC','pr_review_commits','pr_review_comments','pr_commits'] # 8\n",
    "\n",
    "\n",
    "repo_head = ['repo_stars','repo_create_time','repo_external_contribution','repo_team_size'] # 4\n",
    "\n",
    "user_head = ['user_followers','user_dev_time','user_experience', 'user_repo_experience','user_main_member',\n",
    "             'user_watched','user_succ_rate'] # 7\n",
    "\n",
    "csv_head1 = pr_head1 + repo_head + user_head\n",
    "\n",
    "length = len(csv_head)\n",
    "cur_time = datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "with open(\"combine_data.csv\", 'w') as f_write:\n",
    "    csv_write = csv.writer(f_write)\n",
    "    csv_head = csv_head1\n",
    "    csv_write.writerow(csv_head)\n",
    "    \n",
    "    for file_name in csv_list:\n",
    "        f_read = open(\"./csv_files/\" + file_name, 'r')\n",
    "        with f_read:\n",
    "            reader = csv.reader(f_read)\n",
    "            count = 0\n",
    "            for read_row in reader:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                write_row = []\n",
    "\n",
    "                \n",
    "                ######## calculate the time difference ##########\n",
    "                created_at = datetime.strptime(read_row[pr_create_at_idx], \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "                merged_at = datetime.strptime(read_row[pr_merged_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                review_at =  datetime.strptime(read_row[pr_first_review_at_idx] + \"Z\", \"%Y-%m-%d %H:%M:%S%z\") \n",
    "                repo_created_at = datetime.strptime(read_row[repo_created_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                user_created_at = datetime.strptime(read_row[user_created_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                \n",
    "                pr_notice_time = merged_at - review_at\n",
    "                pr_review_time = review_at - created_at\n",
    "                repo_create_time = cur_time - repo_created_at\n",
    "                user_create_time = cur_time - user_created_at\n",
    "                ######### get the author race ##########\n",
    "                author_name = read_row[pr_author_name_idx]\n",
    "                pr_author_race = race_dic[author_name]\n",
    "\n",
    "                ## pr features\n",
    "                write_row.append(pr_author_race)\n",
    "                write_row.append(pr_notice_time.days)\n",
    "                write_row.append(pr_review_time.days)\n",
    "                write_row.append(read_row[pr_changed_files_idx])\n",
    "                write_row.append(read_row[pr_LOC_idx])\n",
    "                write_row.append(read_row[pr_review_commits_idx])\n",
    "                write_row.append(read_row[pr_review_comments_idx])\n",
    "                write_row.append(read_row[pr_commits_idx])\n",
    "                \n",
    "                ## repo features\n",
    "                write_row.append(read_row[repo_stars_idx])\n",
    "                write_row.append(repo_create_time.days)\n",
    "                write_row.append(read_row[repo_external_contribution_idx])\n",
    "                write_row.append(read_row[repo_team_size_idx])\n",
    "\n",
    "                ## user features\n",
    "                write_row.append(read_row[user_followers_idx])\n",
    "                write_row.append(user_create_time.days)\n",
    "                write_row.append(read_row[user_experience_idx])\n",
    "                write_row.append(read_row[user_repo_experience_idx])\n",
    "                write_row.append(read_row[user_main_member_idx])\n",
    "                write_row.append(read_row[user_watched_idx])\n",
    "                write_row.append(read_row[user_succ_rate_idx])\n",
    "                \n",
    "                csv_write.writerow(write_row)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "through-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### build the data for hypo 5 ##########\n",
    "pr_head5 = ['pr_author_race','pr_notice_time','pr_review_time','pr_changed_files',\n",
    "    'pr_LOC','pr_reviewer_race','pr_review_commits','pr_review_comments','pr_commits'] # 9\n",
    "\n",
    "csv_head5 = pr_head5 + repo_head + user_head\n",
    "\n",
    "with open(\"combine_data_h5.csv\", 'w') as f_write:\n",
    "    csv_write = csv.writer(f_write)\n",
    "    csv_head = csv_head5\n",
    "    csv_write.writerow(csv_head)\n",
    "    \n",
    "    for file_name in csv_list:\n",
    "        f_read = open(\"./csv_files/\" + file_name, 'r')\n",
    "        with f_read:\n",
    "            reader = csv.reader(f_read)\n",
    "            count = 0\n",
    "            for read_row in reader:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                write_row = []\n",
    "\n",
    "                \n",
    "                ######## calculate the time difference ##########\n",
    "                created_at = datetime.strptime(read_row[pr_create_at_idx], \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "                merged_at = datetime.strptime(read_row[pr_merged_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                review_at =  datetime.strptime(read_row[pr_first_review_at_idx] + \"Z\", \"%Y-%m-%d %H:%M:%S%z\") \n",
    "                repo_created_at = datetime.strptime(read_row[repo_created_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                user_created_at = datetime.strptime(read_row[user_created_at_idx], \"%Y-%m-%dT%H:%M:%S%z\") \n",
    "                \n",
    "                pr_notice_time = merged_at - review_at\n",
    "                pr_review_time = review_at - created_at\n",
    "                repo_create_time = cur_time - repo_created_at\n",
    "                user_create_time = cur_time - user_created_at\n",
    "                ######### get the author and reviewer race ##########\n",
    "                author_name = read_row[pr_author_name_idx]\n",
    "                pr_author_race = race_dic[author_name]\n",
    "                \n",
    "                reviewer_list = set_string(read_row[pr_reviewers_idx])\n",
    "                if len(reviewer_list) != 1:\n",
    "                    continue\n",
    "                reviewer_race = race_dic[reviewer_list[0]]\n",
    "                \n",
    "                ## pr features\n",
    "                write_row.append(pr_author_race)\n",
    "                write_row.append(pr_notice_time.days)\n",
    "                write_row.append(pr_review_time.days)\n",
    "                write_row.append(read_row[pr_changed_files_idx])\n",
    "                write_row.append(read_row[pr_LOC_idx])\n",
    "                write_row.append(reviewer_race)\n",
    "                write_row.append(read_row[pr_review_commits_idx])\n",
    "                write_row.append(read_row[pr_review_comments_idx])\n",
    "                write_row.append(read_row[pr_commits_idx])\n",
    "                \n",
    "                ## repo features\n",
    "                write_row.append(read_row[repo_stars_idx])\n",
    "                write_row.append(repo_create_time.days)\n",
    "                write_row.append(read_row[repo_external_contribution_idx])\n",
    "                write_row.append(read_row[repo_team_size_idx])\n",
    "\n",
    "                ## user features\n",
    "                write_row.append(read_row[user_followers_idx])\n",
    "                write_row.append(user_create_time.days)\n",
    "                write_row.append(read_row[user_experience_idx])\n",
    "                write_row.append(read_row[user_repo_experience_idx])\n",
    "                write_row.append(read_row[user_main_member_idx])\n",
    "                write_row.append(read_row[user_watched_idx])\n",
    "                write_row.append(read_row[user_succ_rate_idx])\n",
    "                \n",
    "                csv_write.writerow(write_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
